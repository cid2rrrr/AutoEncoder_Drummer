{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_io'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KIST\\Documents\\GitHub\\AutoEncoder_Drummer\\Unet.ipynb ì…€ 1\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KIST/Documents/GitHub/AutoEncoder_Drummer/Unet.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KIST/Documents/GitHub/AutoEncoder_Drummer/Unet.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_io\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfio\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KIST/Documents/GitHub/AutoEncoder_Drummer/Unet.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KIST/Documents/GitHub/AutoEncoder_Drummer/Unet.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_io'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow_addons import layers as addon_layers\n",
    "\n",
    "# Setting logger level to avoid input shape warnings\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# Defining hyperparameters\n",
    "\n",
    "DESIRED_SAMPLES = 8192\n",
    "LEARNING_RATE_GEN = 1e-5\n",
    "LEARNING_RATE_DISC = 1e-6\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "mse = keras.losses.MeanSquaredError()\n",
    "mae = keras.losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing splits\n",
    "wavs = tf.io.gfile.glob(\"./LOOP/*.wav\")\n",
    "print(f\"Number of audio files: {len(wavs)}\")\n",
    "\n",
    "# Mapper function for loading the audio. This function returns two instances of the wave\n",
    "def preprocess(filename):\n",
    "    audio = tf.audio.decode_wav(tf.io.read_file(filename), 1, DESIRED_SAMPLES).audio\n",
    "    return audio, audio\n",
    "\n",
    "\n",
    "# Create tf.data.Dataset objects and apply preprocessing\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((wavs,))\n",
    "train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MelSpec(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        frame_length=1024,\n",
    "        frame_step=256,\n",
    "        fft_length=None,\n",
    "        sampling_rate=22050,\n",
    "        num_mel_channels=80,\n",
    "        freq_min=125,\n",
    "        freq_max=7600,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_step = frame_step\n",
    "        self.fft_length = fft_length\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.num_mel_channels = num_mel_channels\n",
    "        self.freq_min = freq_min\n",
    "        self.freq_max = freq_max\n",
    "        # Defining mel filter. This filter will be multiplied with the STFT output\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=self.num_mel_channels,\n",
    "            num_spectrogram_bins=self.frame_length // 2 + 1,\n",
    "            sample_rate=self.sampling_rate,\n",
    "            lower_edge_hertz=self.freq_min,\n",
    "            upper_edge_hertz=self.freq_max,\n",
    "        )\n",
    "\n",
    "    def call(self, audio, training=True):\n",
    "        # We will only perform the transformation during training.\n",
    "        if training:\n",
    "            # Taking the Short Time Fourier Transform. Ensure that the audio is padded.\n",
    "            # In the paper, the STFT output is padded using the 'REFLECT' strategy.\n",
    "            stft = tf.signal.stft(\n",
    "                tf.squeeze(audio, -1),\n",
    "                self.frame_length,\n",
    "                self.frame_step,\n",
    "                self.fft_length,\n",
    "                pad_end=True,\n",
    "            )\n",
    "\n",
    "            # Taking the magnitude of the STFT output\n",
    "            magnitude = tf.abs(stft)\n",
    "\n",
    "            # Multiplying the Mel-filterbank with the magnitude and scaling it using the db scale\n",
    "            mel = tf.matmul(tf.square(magnitude), self.mel_filterbank)\n",
    "            log_mel_spec = tfio.audio.dbscale(mel, top_db=80)\n",
    "            return log_mel_spec\n",
    "        else:\n",
    "            return audio\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MelSpec, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"frame_length\": self.frame_length,\n",
    "                \"frame_step\": self.frame_step,\n",
    "                \"fft_length\": self.fft_length,\n",
    "                \"sampling_rate\": self.sampling_rate,\n",
    "                \"num_mel_channels\": self.num_mel_channels,\n",
    "                \"freq_min\": self.freq_min,\n",
    "                \"freq_max\": self.freq_max,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def residual_stack(input, filters):\n",
    "    \"\"\"Convolutional residual stack with weight normalization.\n",
    "\n",
    "    Args:\n",
    "        filter: int, determines filter size for the residual stack.\n",
    "\n",
    "    Returns:\n",
    "        Residual stack output.\n",
    "    \"\"\"\n",
    "    c1 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n",
    "    )(input)\n",
    "    lrelu1 = layers.LeakyReLU()(c1)\n",
    "    c2 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n",
    "    )(lrelu1)\n",
    "    add1 = layers.Add()([c2, input])\n",
    "\n",
    "    lrelu2 = layers.LeakyReLU()(add1)\n",
    "    c3 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(filters, 3, dilation_rate=3, padding=\"same\"), data_init=False\n",
    "    )(lrelu2)\n",
    "    lrelu3 = layers.LeakyReLU()(c3)\n",
    "    c4 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n",
    "    )(lrelu3)\n",
    "    add2 = layers.Add()([add1, c4])\n",
    "\n",
    "    lrelu4 = layers.LeakyReLU()(add2)\n",
    "    c5 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(filters, 3, dilation_rate=9, padding=\"same\"), data_init=False\n",
    "    )(lrelu4)\n",
    "    lrelu5 = layers.LeakyReLU()(c5)\n",
    "    c6 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n",
    "    )(lrelu5)\n",
    "    add3 = layers.Add()([c6, add2])\n",
    "\n",
    "    return add3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(input, conv_dim, upsampling_factor):\n",
    "    \"\"\"Dilated Convolutional Block with weight normalization.\n",
    "\n",
    "    Args:\n",
    "        conv_dim: int, determines filter size for the block.\n",
    "        upsampling_factor: int, scale for upsampling.\n",
    "\n",
    "    Returns:\n",
    "        Dilated convolution block.\n",
    "    \"\"\"\n",
    "    conv_t = addon_layers.WeightNormalization(\n",
    "        layers.Conv1DTranspose(conv_dim, 16, upsampling_factor, padding=\"same\"),\n",
    "        data_init=False,\n",
    "    )(input)\n",
    "    lrelu1 = layers.LeakyReLU()(conv_t)\n",
    "    res_stack = residual_stack(lrelu1, conv_dim)\n",
    "    lrelu2 = layers.LeakyReLU()(res_stack)\n",
    "    return lrelu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_block(input):\n",
    "    conv1 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(16, 15, 1, \"same\"), data_init=False\n",
    "    )(input)\n",
    "    lrelu1 = layers.LeakyReLU()(conv1)\n",
    "    conv2 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(64, 41, 4, \"same\", groups=4), data_init=False\n",
    "    )(lrelu1)\n",
    "    lrelu2 = layers.LeakyReLU()(conv2)\n",
    "    conv3 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(256, 41, 4, \"same\", groups=16), data_init=False\n",
    "    )(lrelu2)\n",
    "    lrelu3 = layers.LeakyReLU()(conv3)\n",
    "    conv4 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(1024, 41, 4, \"same\", groups=64), data_init=False\n",
    "    )(lrelu3)\n",
    "    lrelu4 = layers.LeakyReLU()(conv4)\n",
    "    conv5 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(1024, 41, 4, \"same\", groups=256), data_init=False\n",
    "    )(lrelu4)\n",
    "    lrelu5 = layers.LeakyReLU()(conv5)\n",
    "    conv6 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(1024, 5, 1, \"same\"), data_init=False\n",
    "    )(lrelu5)\n",
    "    lrelu6 = layers.LeakyReLU()(conv6)\n",
    "    conv7 = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(1, 3, 1, \"same\"), data_init=False\n",
    "    )(lrelu6)\n",
    "    return [lrelu1, lrelu2, lrelu3, lrelu4, lrelu5, lrelu6, conv7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(input_shape):\n",
    "    inp = keras.Input(input_shape)\n",
    "    x = MelSpec()(inp)\n",
    "    x = layers.Conv1D(512, 7, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = conv_block(x, 256, 8)\n",
    "    x = conv_block(x, 128, 8)\n",
    "    x = conv_block(x, 64, 2)\n",
    "    x = conv_block(x, 32, 2)\n",
    "    x = addon_layers.WeightNormalization(\n",
    "        layers.Conv1D(1, 7, padding=\"same\", activation=\"tanh\")\n",
    "    )(x)\n",
    "    return keras.Model(inp, x)\n",
    "\n",
    "\n",
    "# We use a dynamic input shape for the generator since the model is fully convolutional\n",
    "generator = create_generator((None, 1))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(input_shape):\n",
    "    inp = keras.Input(input_shape)\n",
    "    out_map1 = discriminator_block(inp)\n",
    "    pool1 = layers.AveragePooling1D()(inp)\n",
    "    out_map2 = discriminator_block(pool1)\n",
    "    pool2 = layers.AveragePooling1D()(pool1)\n",
    "    out_map3 = discriminator_block(pool2)\n",
    "    return keras.Model(inp, [out_map1, out_map2, out_map3])\n",
    "\n",
    "\n",
    "# We use a dynamic input shape for the discriminator\n",
    "# This is done because the input shape for the generator is unknown\n",
    "discriminator = create_discriminator((None, 1))\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generator_loss(real_pred, fake_pred):\n",
    "    \"\"\"Loss function for the generator.\n",
    "\n",
    "    Args:\n",
    "        real_pred: Tensor, output of the ground truth wave passed through the discriminator.\n",
    "        fake_pred: Tensor, output of the generator prediction passed through the discriminator.\n",
    "\n",
    "    Returns:\n",
    "        Loss for the generator.\n",
    "    \"\"\"\n",
    "    gen_loss = []\n",
    "    for i in range(len(fake_pred)):\n",
    "        gen_loss.append(mse(tf.ones_like(fake_pred[i][-1]), fake_pred[i][-1]))\n",
    "\n",
    "    return tf.reduce_mean(gen_loss)\n",
    "\n",
    "\n",
    "def feature_matching_loss(real_pred, fake_pred):\n",
    "    \"\"\"Implements the feature matching loss.\n",
    "\n",
    "    Args:\n",
    "        real_pred: Tensor, output of the ground truth wave passed through the discriminator.\n",
    "        fake_pred: Tensor, output of the generator prediction passed through the discriminator.\n",
    "\n",
    "    Returns:\n",
    "        Feature Matching Loss.\n",
    "    \"\"\"\n",
    "    fm_loss = []\n",
    "    for i in range(len(fake_pred)):\n",
    "        for j in range(len(fake_pred[i]) - 1):\n",
    "            fm_loss.append(mae(real_pred[i][j], fake_pred[i][j]))\n",
    "\n",
    "    return tf.reduce_mean(fm_loss)\n",
    "\n",
    "\n",
    "def discriminator_loss(real_pred, fake_pred):\n",
    "    \"\"\"Implements the discriminator loss.\n",
    "\n",
    "    Args:\n",
    "        real_pred: Tensor, output of the ground truth wave passed through the discriminator.\n",
    "        fake_pred: Tensor, output of the generator prediction passed through the discriminator.\n",
    "\n",
    "    Returns:\n",
    "        Discriminator Loss.\n",
    "    \"\"\"\n",
    "    real_loss, fake_loss = [], []\n",
    "    for i in range(len(real_pred)):\n",
    "        real_loss.append(mse(tf.ones_like(real_pred[i][-1]), real_pred[i][-1]))\n",
    "        fake_loss.append(mse(tf.zeros_like(fake_pred[i][-1]), fake_pred[i][-1]))\n",
    "\n",
    "    # Calculating the final discriminator loss after scaling\n",
    "    disc_loss = tf.reduce_mean(real_loss) + tf.reduce_mean(fake_loss)\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelGAN(keras.Model):\n",
    "    def __init__(self, generator, discriminator, **kwargs):\n",
    "        \"\"\"MelGAN trainer class\n",
    "\n",
    "        Args:\n",
    "            generator: keras.Model, Generator model\n",
    "            discriminator: keras.Model, Discriminator model\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        gen_optimizer,\n",
    "        disc_optimizer,\n",
    "        generator_loss,\n",
    "        feature_matching_loss,\n",
    "        discriminator_loss,\n",
    "    ):\n",
    "        \"\"\"MelGAN compile method.\n",
    "\n",
    "        Args:\n",
    "            gen_optimizer: keras.optimizer, optimizer to be used for training\n",
    "            disc_optimizer: keras.optimizer, optimizer to be used for training\n",
    "            generator_loss: callable, loss function for generator\n",
    "            feature_matching_loss: callable, loss function for feature matching\n",
    "            discriminator_loss: callable, loss function for discriminator\n",
    "        \"\"\"\n",
    "        super().compile()\n",
    "\n",
    "        # Optimizers\n",
    "        self.gen_optimizer = gen_optimizer\n",
    "        self.disc_optimizer = disc_optimizer\n",
    "\n",
    "        # Losses\n",
    "        self.generator_loss = generator_loss\n",
    "        self.feature_matching_loss = feature_matching_loss\n",
    "        self.discriminator_loss = discriminator_loss\n",
    "\n",
    "        # Trackers\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"gen_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"disc_loss\")\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        x_batch_train, y_batch_train = batch\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            # Generating the audio wave\n",
    "            gen_audio_wave = generator(x_batch_train, training=True)\n",
    "\n",
    "            # Generating the features using the discriminator\n",
    "            fake_pred = discriminator(y_batch_train)\n",
    "            real_pred = discriminator(gen_audio_wave)\n",
    "\n",
    "            # Calculating the generator losses\n",
    "            gen_loss = generator_loss(real_pred, fake_pred)\n",
    "            fm_loss = feature_matching_loss(real_pred, fake_pred)\n",
    "\n",
    "            # Calculating final generator loss\n",
    "            gen_fm_loss = gen_loss + 10 * fm_loss\n",
    "\n",
    "            # Calculating the discriminator losses\n",
    "            disc_loss = discriminator_loss(real_pred, fake_pred)\n",
    "\n",
    "        # Calculating and applying the gradients for generator and discriminator\n",
    "        grads_gen = gen_tape.gradient(gen_fm_loss, generator.trainable_weights)\n",
    "        grads_disc = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n",
    "        gen_optimizer.apply_gradients(zip(grads_gen, generator.trainable_weights))\n",
    "        disc_optimizer.apply_gradients(zip(grads_disc, discriminator.trainable_weights))\n",
    "\n",
    "        self.gen_loss_tracker.update_state(gen_fm_loss)\n",
    "        self.disc_loss_tracker.update_state(disc_loss)\n",
    "\n",
    "        return {\n",
    "            \"gen_loss\": self.gen_loss_tracker.result(),\n",
    "            \"disc_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = keras.optimizers.Adam(\n",
    "    LEARNING_RATE_GEN, beta_1=0.5, beta_2=0.9, clipnorm=1\n",
    ")\n",
    "disc_optimizer = keras.optimizers.Adam(\n",
    "    LEARNING_RATE_DISC, beta_1=0.5, beta_2=0.9, clipnorm=1\n",
    ")\n",
    "\n",
    "# Start training\n",
    "generator = create_generator((None, 1))\n",
    "discriminator = create_discriminator((None, 1))\n",
    "\n",
    "mel_gan = MelGAN(generator, discriminator)\n",
    "mel_gan.compile(\n",
    "    gen_optimizer,\n",
    "    disc_optimizer,\n",
    "    generator_loss,\n",
    "    feature_matching_loss,\n",
    "    discriminator_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_gan.fit(\n",
    "    train_dataset.shuffle(200).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE), epochs=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spleeter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b3c401dacfab8a690b1a7de6c6a9edd3269fc10d243267328a900f27334b3a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
